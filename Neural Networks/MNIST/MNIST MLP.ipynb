{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will implement a Multi Layer Perceptron using tensorflow and the famous MNIST dataset. We won't use keras to implement the nueral network as this is a specific exercise on the use of Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: dict of bias values\n",
    "    '''\n",
    "    # First Hidden Layer with RELU Activation\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Func(X * W + B) -> f(x) = max(0, x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden Layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output Layer\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train shape\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2].reshape(28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize one of the training image to see how it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14f81318710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f81290ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "We now define the hyperparameters of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the number of neurons of the two hidden layers equal to 256, this number is chosen because of the way computer stores images information (8 bit color storage). The number of classes is equal to 10 since the output of our neural network will be a vector of 10 elements.\n",
    "\n",
    "For example an output of this type [0 0 0 0 0 0 1 0 0 0 ] will represent a 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = mnist.train.num_examples\n",
    "n_inputs = 784\n",
    "n_hidden_neurons1 = 256\n",
    "n_hidden_neurons2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a dictionary containing the weights of the two hidden layers and of the output layer. We initialize these weights at random  using a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_inputs, n_hidden_neurons1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_neurons1, n_hidden_neurons2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_neurons2,n_classes])) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the biases in the same way, as we have done for the weights, using a random normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_neurons1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_neurons2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes])) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_inputs])\n",
    "y = tf.placeholder('float', [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use softmax cross entropy as cost function and 'Adam' optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred,labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost 0.0810\n",
      "Epoch: 2 cost 0.0410\n",
      "Epoch: 3 cost 0.0387\n",
      "Epoch: 4 cost 0.0206\n",
      "Epoch: 5 cost 0.0063\n",
      "Epoch: 6 cost 0.0067\n",
      "Epoch: 7 cost 0.0210\n",
      "Epoch: 8 cost 0.0129\n",
      "Epoch: 9 cost 0.0132\n",
      "Epoch: 10 cost 0.0004\n",
      "Epoch: 11 cost 0.0113\n",
      "Epoch: 12 cost 0.0051\n",
      "Epoch: 13 cost 0.0072\n",
      "Epoch: 14 cost 0.0001\n",
      "Epoch: 15 cost 0.0068\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # Cost\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _,c = sess.run([optimizer,cost],feed_dict = {x: batch_x, y:batch_y})\n",
    "        avg_cost = c/total_batch\n",
    "    \n",
    "    print(\"Epoch: {} cost {:.4f}\".format(epoch+1, avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, 'float')\n",
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94389999"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x:mnist.test.images, y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with an higher number of epochs like 10000 it is possible to obtain an accuracy of 99 %. We won't do this here since this was just an exercise on the use of Tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
